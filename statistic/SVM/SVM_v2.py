# -*- coding: utf-8 -*-
"""
SVM Classification Script for ADHD Slow Wave and Behavioral Data
This script performs SVM classification to distinguish between different participant groups
based on global slow wave parameters and behavioral data.

Tasks performed:
1. Load data from an Excel file.
2. Preprocess data for specific comparison groups.
3. Train and evaluate an SVM model for:
    a) Healthy Controls (HC) vs. All ADHD participants
    b) ADHD-I vs. ADHD-C subtypes
4. Report key performance metrics including accuracy, precision, recall, F1-score,
   confusion matrix, and ROC curve.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, RocCurveDisplay
from imblearn.over_sampling import RandomOverSampler

# --- 1. Parameters and Configuration (å‚æ•°è®¾ç½®) ---

# TODO: Fill in your file path and sheet name
# TODO: è¯·åœ¨è¿™é‡Œå¡«å…¥ä½ çš„Excelæ–‡ä»¶åå’Œå·¥ä½œè¡¨å
FILE_PATH = 'antç½‘ç»œé›·è¾¾å›¾.xlsx'  # <-- ä¿®æ”¹è¿™é‡Œ
SHEET_NAME = 'Sheet1'  # <-- ä¿®æ”¹è¿™é‡Œ (å¦‚æœéœ€è¦)

# Define the feature columns to be used in the model
# å®šä¹‰æ¨¡å‹è¦ä½¿ç”¨çš„ç‰¹å¾åˆ—
# These should match the column names in your Excel file
# è¿™äº›åˆ—åéœ€è¦å’Œä½ çš„Excelæ–‡ä»¶ä¸­çš„åˆ—åå®Œå…¨ä¸€è‡´

FEATURE_COLUMNS = [
    # 'Age',  # å¹´é¾„
    # 'Accuracy',  # è¡Œä¸ºå­¦ - å‡†ç¡®ç‡ (ACC)
    # 'Response Time',  # è¡Œä¸ºå­¦ - ååº”æ—¶ (RT)
    # 'Alerting',  # ANT - è­¦è§‰ç½‘ç»œ
    # 'Orienting',  # ANT - å®šå‘ç½‘ç»œ
    # 'Executive Control',  # ANT - æ‰§è¡Œæ§åˆ¶ç½‘ç»œ
    # 'maxnegpkamp',  # æ…¢æ³¢å‚æ•° - æœ€å¤§è´Ÿæ³¢å¹…
    # 'maxnegpkamp_1',
    # 'maxnegpkamp_3',
    # 'maxnegpkamp_5',
    # 'maxnegpkamp_7',
    # 'maxnegpkamp_9',
    # 'maxnegpkamp_10',
    # 'maxnegpkamp_12',
    # 'maxnegpkamp_cluster1',
    # 'maxnegpkamp_cluster2',
    'maxnegpkamp_cluster',
    # 'maxnegpkamp/mxdnslp_1',
    # 'mxdnslp_1',
    # 'mxdnslp_3',
    # 'mxdnslp_4',
    # 'mxdnslp_5',
    # 'mxdnslp_7',
    # 'mxdnslp_8',
    # 'mxdnslp_9',
    # 'mxdnslp_12',
    # 'mxdnslp_14',
    # 'mxdnslp_18',
    # 'mxdnslp_cluster1',
    # 'mxdnslp_cluster2',
    'mxdnslp_cluster',
    'mxupslp_cluster',
    # 'mxupslp_1',
    # 'mxupslp_3',
    # 'mxupslp_7',
    # 'mxupslp_5',
    # 'maxpospkamp',  # æ…¢æ³¢å‚æ•° - æœ€å¤§æ­£æ³¢å¹…
    # 'mxdnslp',  # æ…¢æ³¢å‚æ•° - æœ€å¤§ä¸‹é™æ–œç‡
    # 'mxupslp',  # æ…¢æ³¢å‚æ•° - æœ€å¤§ä¸Šå‡æ–œç‡
    # 'sw_density',  # æ…¢æ³¢å‚æ•° - æ…¢æ³¢å¯†åº¦
    # 'mean_duration'  # æ…¢æ³¢å‚æ•° - å¹³å‡æŒç»­æ—¶é—´
]
# Define group IDs as they appear in your data file
# å®šä¹‰æ•°æ®æ–‡ä»¶ä¸­çš„ç»„åˆ«ID
GROUP_HC = 0  # å¥åº·å„¿ç«¥ (Healthy Controls)
GROUP_ADHD1 = 1  # ADHD-I å‹
GROUP_ADHD3 = 3  # ADHD-C å‹ (å‡è®¾æ··åˆå‹æ˜¯3, è¯·æ ¹æ®ä½ çš„æ•°æ®ä¿®æ”¹)


# --- 2. Data Loading and Preparation Functions (æ•°æ®åŠ è½½ä¸å‡†å¤‡å‡½æ•°) ---

def load_data(file_path, sheet_name):
    """Loads data from the specified Excel file."""
    # """ä»æŒ‡å®šçš„Excelæ–‡ä»¶åŠ è½½æ•°æ®ã€‚"""
    try:
        df = pd.read_excel(file_path, sheet_name=sheet_name)
        print(f"âœ… Data successfully loaded from '{file_path}'.")
        print(f"Total participants in file: {len(df)}")
        return df
    except FileNotFoundError:
        print(f"âŒ ERROR: File not found at '{file_path}'. Please check the file path.")
        return None


def prepare_data(df, features, target_groups, target_column='Group'):
    """
    Prepares data for a specific classification task by filtering groups
    and separating features (X) from the target (y).
    """
    # """ä¸ºç‰¹å®šåˆ†ç±»ä»»åŠ¡å‡†å¤‡æ•°æ®ï¼šç­›é€‰ç»„åˆ«ï¼Œå¹¶åˆ†ç¦»ç‰¹å¾(X)å’Œç›®æ ‡(y)ã€‚"""

    # Filter for the groups of interest
    df_filtered = df[df[target_column].isin(target_groups)].copy()

    # Handle missing values by dropping rows with any missing data in the required columns
    df_filtered.dropna(subset=features + [target_column], inplace=True)

    if len(df_filtered) < 10:  # Check if there's enough data
        print(f"âš ï¸ Warning: Not enough data for groups {target_groups}. Found only {len(df_filtered)} samples.")
        return None, None

    # Define features (X) and target (y)
    X = df_filtered[features]
    y = df_filtered[target_column]

    # Map group labels to binary 0 and 1 for SVM
    # å°†ç»„åˆ«æ ‡ç­¾æ˜ å°„ä¸º0å’Œ1ï¼Œä»¥ä¾›SVMä½¿ç”¨
    y = y.map({target_groups[0]: 0, target_groups[1]: 1})

    print(f"Data prepared for groups {target_groups}.")
    print(f"Number of samples: {len(X)}. Class distribution:\n{y.value_counts()}")

    return X, y


# --- 3. SVM Model Training and Evaluation Function (SVMæ¨¡å‹è®­ç»ƒä¸è¯„ä¼°å‡½æ•°) ---

def run_svm_classification(X, y, model_name="SVM Classification"):
    """
    Trains an SVM classifier, evaluates it using cross-validation and a test set,
    and visualizes the results.
    """
    # """è®­ç»ƒä¸€ä¸ªSVMåˆ†ç±»å™¨ï¼Œä½¿ç”¨äº¤å‰éªŒè¯å’Œæµ‹è¯•é›†è¿›è¡Œè¯„ä¼°ï¼Œå¹¶å¯è§†åŒ–ç»“æœã€‚"""

    # --- Feature Scaling (ç‰¹å¾ç¼©æ”¾) ---
    # SVMs are sensitive to feature scales, so we standardize them.
    # SVMå¯¹ç‰¹å¾çš„å°ºåº¦å¾ˆæ•æ„Ÿï¼Œå› æ­¤æˆ‘ä»¬è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ã€‚
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # --- Cross-Validation (äº¤å‰éªŒè¯) ---
    # Use 5-fold cross-validation to get a robust estimate of model performance.
    # ä½¿ç”¨5æŠ˜äº¤å‰éªŒè¯æ¥è·å¾—å¯¹æ¨¡å‹æ€§èƒ½æ›´ç¨³å¥çš„è¯„ä¼°ã€‚
    # We use a linear kernel as a starting point. An RBF kernel ('rbf') is another good option.
    # æˆ‘ä»¬ä½¿ç”¨çº¿æ€§æ ¸å‡½æ•°(linear)ä½œä¸ºèµ·ç‚¹ï¼ŒRBFæ ¸å‡½æ•°('rbf')æ˜¯å¦ä¸€ä¸ªå¾ˆå¥½çš„é€‰æ‹©ã€‚
    model_cv = SVC(kernel='linear', random_state=42)
    cv_scores = cross_val_score(model_cv, X_scaled, y, cv=5, scoring='accuracy')
    print("\n--- Cross-Validation Results ---")
    print(f"Mean Accuracy (5-fold CV): {np.mean(cv_scores):.3f} (Â± {np.std(cv_scores):.3f})")

    # --- Train-Test Split for Final Evaluation (åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ç”¨äºæœ€ç»ˆè¯„ä¼°) ---
    # Split data into 80% for training and 20% for testing.
    # `stratify=y` ensures the class proportions are the same in train and test sets.
    # stratify=y ç¡®ä¿è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­çš„ç±»åˆ«æ¯”ä¾‹ä¿æŒä¸€è‡´ã€‚
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.25, random_state=42, stratify=y
    )

    # --- Model Training and Prediction (æ¨¡å‹è®­ç»ƒä¸é¢„æµ‹) ---
    # Initialize the final model. `probability=True` is needed for ROC curve plotting.
    # åˆå§‹åŒ–æœ€ç»ˆæ¨¡å‹ã€‚probability=True æ˜¯ç»˜åˆ¶ROCæ›²çº¿æ‰€å¿…éœ€çš„ã€‚
    model = SVC(kernel='linear', probability=True, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # --- Evaluation on Test Set (åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°) ---
    print("\n--- Test Set Evaluation Results ---")
    print(classification_report(y_test, y_pred))

    print("Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred))

    # --- Visualization (ç»“æœå¯è§†åŒ–) ---
    # fig, ax = plt.subplots(1, 1, figsize=(8, 6))

    # Plot ROC Curve
    # RocCurveDisplay.from_estimator(model, X_test, y_test, ax=ax, name=model_name)
    # ax.plot([0, 1], [0, 1], 'k--', label='Chance Level (AUC = 0.5)')  # Add chance line
    # ax.set_title(f'ROC Curve for {model_name}')
    # ax.legend()

    plt.tight_layout()
    plt.show()


# --- 4. Main Execution Block (ä¸»æ‰§è¡Œæ¨¡å—) ---

if __name__ == "__main__":
    # Load the data first
    df_main = load_data(FILE_PATH, SHEET_NAME)

    if df_main is not None:
        # ===================================================================
        # Task 1: Healthy Controls (HC) vs. All ADHD Classification
        # ä»»åŠ¡ä¸€: å¥åº·å„¿ç«¥ (HC) vs. æ‰€æœ‰ADHD
        # ===================================================================
        print("\n" + "=" * 50)
        print("ğŸš€ Task 1: Healthy Controls vs. All ADHD")
        print("=" * 50)

        # Create a temporary column to group all ADHD subtypes together
        df_task1 = df_main.copy()
        # Create a new binary target column: 0 for HC, 1 for ADHD
        df_task1['ADHD_binary'] = df_task1['Group'].apply(lambda x: 0 if x == GROUP_HC else 1)

        X1, y1 = prepare_data(df_task1, FEATURE_COLUMNS, [0, 1], target_column='ADHD_binary')

        if X1 is not None and y1 is not None:
            run_svm_classification(X1, y1, model_name="HC vs. All ADHD")
        else:
            print("Skipping Task 1 due to insufficient data.")

        # ===================================================================
        # Task 2: ADHD-I vs. ADHD-C Classification
        # ä»»åŠ¡äºŒ: ADHD-I vs. ADHD-C
        # ===================================================================
        print("\n" + "=" * 50)
        print("ğŸš€ Task 2: ADHD-I vs. ADHD-C Subtype Classification")
        print("=" * 50)

        X2, y2 = prepare_data(df_main, FEATURE_COLUMNS, [GROUP_ADHD1, GROUP_ADHD3], target_column='Group')

        if X2 is not None and y2 is not None:
            run_svm_classification(X2, y2, model_name="ADHD-I vs. ADHD-C")
        else:
            print("Skipping Task 2 due to insufficient data.")

    print("\nâœ… All tasks complete.")